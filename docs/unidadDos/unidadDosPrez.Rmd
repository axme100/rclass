---
title: "Unidad 2"
subtitle: "R Studio y El Tidyverse"
author: "Max Carey"
date: "UNAM </br> `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["lucy", "lucy-fonts"]
    nature:
      beforeInit: "http://www.jvcasillas.com/ru_xaringan/js/ru_xaringan.js"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(wordcloud2)
library(kableExtra)
```

class: center, middle

# xaringan

### /ʃæ.'riŋ.ɡæn/

---

- Vamos a utilizar datos lexicográficos (y unos datos de mi tesis)

```{r, out.width = "50px", echo=FALSE}
knitr::include_graphics("https://wordery.com/jackets/e7071a1a/m/a-frequency-dictionary-of-spanish-mark-davies-9780415334297.jpg")
```

--

- Utiliza git para clonar el archivo de esta clase:
```{r, engine = 'bash', eval = FALSE}
git clone https://github.com/axme100/rclass
```

--

- Utiliza shell para sacar la carpeta `starterPack`
```{r, engine = 'bash', eval = FALSE}
git clone https://github.com/axme100/rclass
```

--

- Borrar rclass `starterPack`
```{r, engine = 'bash', eval = FALSE}
rm -r rclass/
```

--

- Haz click en `myScript.R`

---
class: inverse, center, middle

# ¿Cómo cargar datos en R Studio?

---
# ¿Cómo cargar datos en R?

--

## Con *Absolute Path*
```{r}
spanLexData <- read.csv("~/Documents/proj/R_class/docs/unidadDos/spanLexData.csv")
```

--

## Con *Relative Path*
```{r}
spanLexData <- read.csv("spanLexData.csv")
```

## En *R Studio*
- Ayuda muchísimo `import dataset`

---

# ¿Cómo son estos datos?

--

## Con `str()`

--

```{r}
str(spanLexData)
```

---

## Con `glimpse()`

--

```{r}
# library(dplyr)
glimpse(spanLexData)
```

---

## Con `unique()`

--

```{r}
unique(spanLexData$pos)
```

---

## Con `View()`

--

```{r}
# View(spanLexData)
```

---

## Con `head()`

--

```{r}
head(spanLexData)
```

---

# ¿Cómo podemos ordenar esta base de datos?

--

```{r}
spanLexData <- spanLexData %>%
  arrange(rank)
```

---

class: inverse, center, middle

# ¿Cómo son los datos?

---

## ¿Qué tan frecuente es la palabra más frecuente?

--

```{r fig.height=5, fig.width=8}
ggplot(spanLexData, aes(y = rawFreq, x = rank))
```

---

## ¿Qué tan frecuente es la palabra más frecuente?

--

```{r fig.height=5, fig.width=8}
ggplot(spanLexData, aes(y = rawFreq, x = rank)) + geom_point()
```

---

## ¿Qué tan frecuente es la palabra más frecuente?

--

```{r fig.height=5, fig.width=8}
ggplot(spanLexData, aes(y = rawFreq, x = rank)) + geom_point() + scale_y_log10()
```

---

## ¿Qué tan frecuente es la palabra más frecuente?

--

```{r fig.height=5, fig.width=8}
ggplot(spanLexData, aes(y = rawFreq, x = rank, color = pos)) + geom_point() + scale_y_log10()
```

---

## Se observa el mismo patrón por cada POS?

--

```{r fig.height=5, fig.width=8}
ggplot(spanLexData, aes(y = rawFreq, x = rank)) + geom_point() + scale_y_log10() + facet_wrap(~pos)
```

---

## ¿Cuál es el POS más frecuente?

### Contar los datos
```{r}
spanLexData %>%
  count(pos)
```

---

## ¿Cuál es el POS más frecuente?

### utilizar arrange para en orden descendente

```{r}
spanLexData %>%
  count(pos) %>%
  arrange(desc(n))
```


---

## ¿Cuál es el POS más frecuente?

Ver los resultados

```{r fig.height=5, fig.width=8}
spanLexData %>%
  count(pos) %>%
  arrange(desc(n)) %>%
ggplot(.,aes(y=n,x=pos)) + geom_col()
```



---

### Reorganizar los factores(opcional)

--

```{r fig.height=5, fig.width=8}
spanLexData %>%
  count(pos) %>%
  arrange(desc(n)) %>%
  mutate(pos = fct_reorder(pos,desc(n))) %>%
ggplot(., aes(y=n,x=pos)) + geom_col()

```

---

## ¿Como obtener una base que solo contine las palabras con una representación sesgada en la parte oral del corpus?

--

```{r}
# library(kableExtra)
spanLexDataOral <- spanLexData %>%
  filter(oral=="high")
```

---

## Confirmar resultados
```{r}
unique(spanLexDataOral$oral)
```

-??????????

-Son los niveles de los factores

--

## Confirmar de otra manera

```{r}
spanLexDataOral %>%
  count(oral)
```


---

class: inverse, center, middle

# Boxplots

---

## Cargar los datos de mi tesis

--

```{r}
maxTesis <- read.csv("maxTesis.csv")
```

---

## ¿Que grupo dialectal tiene realizaciones de la /d/ intervocálica más debilitadas?

--

```{r fig.height=5, fig.width=8}
ggplot(maxTesis, aes(y=intensityDif, x = grupo)) + geom_boxplot()
```

---

# ¿Como hacer un WordCloud?
```{r}
wordCloudData <- spanLexData %>%
  select(headword,rawFreq) %>%
  # Selecionar las filas de 100 a n()
  # https://stackoverflow.com/a/42238006/5420796
  slice(100:n())

wordcloud2(wordCloudData)
```
---